{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e58baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885c3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "poses = mp_pose.Pose(\n",
    "    static_image_mode=False,  #静止画かどうか\n",
    "    # UPPER_BODY_ONLY=False,   #上半身のみかどうか\n",
    "    # SMOOTH_LANDMARKS=True,   #ジッターを減らすかどうか\n",
    "    min_detection_confidence=0.7, #検出成功の最低信頼値\n",
    "    min_tracking_confidence=0.7 #追跡成功の最小信頼値\n",
    "     ) \n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "vid = cv2.VideoCapture(\"mv/umap.mp4\")\n",
    "# 59.94fps 1920p1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2d63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n"
     ]
    }
   ],
   "source": [
    "print(vid.get(cv2.CAP_PROP_FPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd1a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 座標をnumpyにする\n",
    "def landmark2np(pose_landmarks):\n",
    "    li = []\n",
    "    for j in (pose_landmarks.landmark):\n",
    "        li.append([j.x, j.y, j.z])\n",
    "\n",
    "    return np.array(li) - li[0]\n",
    "\n",
    "# コサイン類似度を計算する\n",
    "def manual_cos(A, B):\n",
    "    dot = np.sum(A*B, axis=-1)\n",
    "    A_norm = np.linalg.norm(A, axis=-1)\n",
    "    B_norm = np.linalg.norm(B, axis=-1)\n",
    "    cos = dot / (A_norm*B_norm+1e-7)\n",
    "    print(cos[1:].mean())\n",
    "\n",
    "    return cos[1:].mean()\n",
    "\n",
    "# 動画を読み込み、FPSを変更して別名で保存する関数\n",
    "def m_speed_change(path_in, path_out, scale_factor, color_flag):\n",
    "    # 動画読み込みの設定\n",
    "    movie = cv2.VideoCapture(path_in)\n",
    " \n",
    "    # 動画ファイル保存用の設定\n",
    "    fps = int(movie.get(cv2.CAP_PROP_FPS))                                  # 元動画のFPSを取得\n",
    "    fps_new = int(fps * scale_factor)                                       # 動画保存時のFPSはスケールファクターをかける\n",
    "    w = int(movie.get(cv2.CAP_PROP_FRAME_WIDTH))                            # 動画の横幅を取得\n",
    "    h = int(movie.get(cv2.CAP_PROP_FRAME_HEIGHT))                           # 動画の縦幅を取得\n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')                     # 動画保存時のfourcc設定（mp4用）\n",
    "    video = cv2.VideoWriter(path_out, fourcc, fps_new, (w, h), color_flag)  # 動画の仕様（ファイル名、fourcc, FPS, サイズ）\n",
    " \n",
    "    # ファイルからフレームを1枚ずつ取得して動画処理後に保存する\n",
    "    while True:\n",
    "        ret, frame = movie.read()        # フレームを取得\n",
    "        video.write(frame)               # 動画を保存する\n",
    "        # フレームが取得できない場合はループを抜ける\n",
    "        if not ret:\n",
    "            break\n",
    "    # 撮影用オブジェクトとウィンドウの解放\n",
    "    movie.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_in = 'mv/afleg.mp4'          # 元動画のパス\n",
    "path_out = 'mv/afleg_render.mp4'      # 保存する動画のパス\n",
    "scale_factor = 10              # FPSにかけるスケールファクター\n",
    "color_flag = True               # カラー動画はTrue, グレースケール動画はFalse\n",
    " \n",
    "# 動画の再生速度を変更する関数を実行\n",
    "m_speed_change(path_in, path_out, scale_factor, color_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_mortion = [None, None, None]\n",
    "start = -100\n",
    "score = [0, 0, 0]\n",
    "saved_no = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  success, img = vid.read()\n",
    "  imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  results = poses.process(imgRGB)\n",
    "\n",
    "  if results.pose_landmarks:\n",
    "         for id,landmark in enumerate(results.pose_landmarks.landmark):\n",
    "              height, width, channel = img.shape #get dimensions(h height, w width) and the c channel of image\n",
    "              cx = int(landmark.x * width)\n",
    "              cy = int(landmark.y * height)\n",
    "              # cv2.circle(img, (cx, cy), 2, (100, 255, 0), cv2.FILLED)0\n",
    "              cv2.putText(img, str(id), (cx+10, cy+10), cv2.FONT_HERSHEY_PLAIN, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "              mp_drawing.draw_landmarks(img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS) \n",
    "\n",
    "            # ポーズの保存\n",
    "\n",
    "              if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "                saved_mortion[0] = landmark2np(results.pose_landmarks)\n",
    "                start = time.time()\n",
    "                saved_no = 1\n",
    "                print('no.1 saved')\n",
    "            \n",
    "              if cv2.waitKey(1) & 0xFF == ord('d'):\n",
    "                saved_mortion[1] = landmark2np(results.pose_landmarks)\n",
    "                start = time.time()\n",
    "                saved_no = 2\n",
    "                print('no.2 saved')\n",
    "            \n",
    "              if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "                saved_mortion[2] = landmark2np(results.pose_landmarks)\n",
    "                start = time.time()\n",
    "                saved_no = 3\n",
    "                print('no.3 saved')\n",
    "\n",
    "              # cos類似度でチェック\n",
    "              if saved_mortion[0] is not None:\n",
    "                  now_array = landmark2np(results.pose_landmarks)\n",
    "                  score[0] = manual_cos(saved_mortion[0], now_array)\n",
    "\n",
    "              if saved_mortion[1] is not None:\n",
    "                  now_array = landmark2np(results.pose_landmarks)\n",
    "                  score[1] = manual_cos(saved_mortion[1], now_array)\n",
    "\n",
    "              if saved_mortion[2] is not None:\n",
    "                  now_array = landmark2np(results.pose_landmarks)\n",
    "                  score[2] = manual_cos(saved_mortion[2], now_array)\n",
    "  # 3s 表示\n",
    "  if time.time() - start < 3:\n",
    "      cv2.putText(img, f'No.{saved_no} saved', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3.0, (255, 255, 255), thickness=2)\n",
    "\n",
    "  elif score[0] > 0.9:\n",
    "      cv2.putText(img, 'no.1 pose', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3.0, (255, 0, 255), thickness=2)\n",
    "\n",
    "  elif score[1] > 0.9:\n",
    "      cv2.putText(img, 'no.2 pose', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3.0, (255, 0, 255), thickness=2)\n",
    "\n",
    "  elif score[2] > 0.9:\n",
    "      cv2.putText(img, 'no.3 pose', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3.0, (255, 0, 255), thickness=2)\n",
    "  cv2.imshow(\"Image\", img)\n",
    "\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0ba41b70675594d343dfa1ccdee2f3960697b61ddc114f4b52eb71cd81cc533"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
